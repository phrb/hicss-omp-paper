\section{Concurrency and Multithreading Programming}
\label{sec:concurrency}

A program is composed of data declarations, assignments and control flow, following the syntax and abstractions of a programming language. A concurrent program is a set of sequential programs that can be executed in parallel~\cite{Ben-Ari:1990}.

In 2004, the first multi-core processor was launched~\cite{Sutter:2005} into the mainstream market. The increasing number of cores of current parallel machines has motivated concurrent execution of tasks in all scientific and commercial domains, although this paradigm may still face some resistance~\cite{FreeLunchIsOver} \cite{threadsProblem:2006} \cite{KISS:2004:article}. Two important concepts are \emph{concurrency} and \emph{parallelism}. Concurrency occurs when multiple tasks are logically active at the same time and parallelism occurs when multiple tasks are actually active at the same time. In this case parallelism is related to physically performing tasks in parallel. In a computer with a multi-core processor we can have physical parallelism.

In practically every language that supports multi-threading, the implementation of this concept follows the idea of having a function with the code to be executed by the thread when it is created. Programming multi-threaded applications is a complex task, independently of the language used. The non determinism that is introduced by the use of threads can be controlled using synchronization mechanisms such as locks \cite{threadsProblem:2006}, semaphores and barriers, but these mechanisms increase the complexity of the program even more. 

In C/C++ languages the \texttt{pthreads} library can be used to control thread execution on GNU/Linux. This library implements the standard POSIX API (IEEE 1003.1c) and provides mechanisms to create and synchronize threads. The choice to use the \texttt{pthreads} library, and not \texttt{OpenMP}, can be motivated by the fact that \texttt{pthreads} is a common library, available on platforms with GNU/Linux, and operates in a lower level of abstraction in comparison with \texttt{OpenMP} threads. The Code~\ref{cod:sample:pthreads} presents a sample of code that uses the \texttt{pthreads} library.

\begin{lstlisting}[style=C, label=cod:sample:pthreads,caption=The Sample of pthreads code.]
int main(){
  pthread_t thread1;
  DATA_TYPE *params = 10;
  int iret1;

  iret1 = pthread_create( &thread1, NULL, task_function, (void*) params);
  printf("Thread 1 return: %d\n", iret1);
  pthread_join(thread1, NULL);
  
  return 0;
}

void *task_function(void *ptr) {
  DATA_TYPE *value;
  value = (DATA_TYPE *) ptr;
  /* Computing */
}
\end{lstlisting}

This sample code shows some important concepts. Until \texttt{line 6} only one thread is executing the main flow of instructions. When the \texttt{pthread\_create()} function is called, a new thread is created and then the application have two threads executing in parallel. For synchronization between threads barriers are necessary. The library implements barriers and they can be used in the code by calling \texttt{pthread\_join()}. In \texttt{line 8} we can see an example of this, where the thread that reaches that point will wait for the completion of other threads to continue the execution of the main flow.

To explain the use of \texttt{pthreads} we use the sample code in Code~\ref{cod:basic} to create a parallel version. The code have a reduction operation, in the multiplication of elements of $A$ and $B$ to the $dot$ variable. In this case, we want to parallelize the loop instances by dividing the amount of instances among a number of threads.

\begin{lstlisting}[style=C, label=cod:basic,caption=Sample of Basic Code.]
 for(i = 0; i < N; i++){
   dot += A[i] * B[i];
 }
\end{lstlisting}

The Code~\ref{cod:sample:vetdot:pthreads} shows a vector product operation that was implemented using \texttt{pthreads}. This example shows that we need to write several lines of code to perform a simple operation like sharing work between threads.

% float=ht 
\begin{lstlisting}[style=C, label=cod:sample:vetdot:pthreads,caption=The vetdot sample using pthreads.]
int A[SIZE], B[SIZE];
int dot = 0;

pthread_mutex_t lock;

int main( int argc, char *argv[] ){
  int num_threads, i, part_size;
  
  pthread_t tid[MAX_THREADS];
	
  pthread_attr_t attr;
  pthread_attr_init(&attr);
	
  /* Initialization vectors was supressed. */
	
  part_size = (SIZE + num_threads - 1) / num_threads;
	
  for (i=0; i < num_threads; i++) {
  	struct arg_struct *args = malloc(sizeof(struct arg_struct));
		
  	args->id = i;
  	args->i_part = (i * part_size);
  	args->e_part = MIN(((i + 1)* (part_size)), SIZE);
  	
  	pthread_create(&(tid[i]), &attr, vecDot, (void *) args);
  }
	
  for (i=0; i<num_threads; i++) {
  	pthread_join(tid[i], NULL);
  }
	
  printf("Final result: %d.\n", dot);
	
  return 0;
}

void *vecDot(void *arguments){
  struct arg_struct *args = arguments;
  int i, partial_dot = 0;	
	
  for(i = args->i_part; i < args->e_part; i++){ 
  	partial_dot += A[i] * B[i]; 
  }
	
  /* Critical region. */
  pthread_mutex_lock(&lock);
  dot += partial_dot;
  pthread_mutex_unlock(&lock);
	
  pthread_exit(0);
}
\end{lstlisting}

In the main function, the arrays are initialized and divided among the number of created threads. Each thread executes the \texttt{vetDot} function, saving the calculated $partial\_dot$ value in the global $dot$ variable. This is done inside a delimited critical region, defined by the use of using \textit{pthread} \textit{mutexes}.