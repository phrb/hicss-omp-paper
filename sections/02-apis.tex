\section{Pthreads \& OpenMP}
\label{sec:apis}

The selection of teaching tools for Parallel and Distributed courses impacts
the development of students' abilities to solve algorithmic problems
efficiently. The importance of selecting good tools for teaching Parallel and
Distributed Computing has been increasingly important, especially since the
topic became a core component of the ACM undergraduate computer science
curricula in 2013~\cite{acmcurricula}.  In this section we briefly describe
\textit{OpenMP} and \textit{Pthreads}, two commonly used tools for parallel and
distributed programming.

\subsection{Pthreads}

The \textit{Pthreads} library specification was designed to provide a standard
and portable API for developing multi-threaded programs for multiple vendor
platforms.  The programming interface was specified by the \textit{IEEE POSIX
1003.1c} standard. Any implementation adhering to this standard is said to be
POSIX threads, or \textit{Pthreads}.

The C/C++ \textit{Pthreads} library controls thread execution in GNU/Linux by
creating and synchronizing threads. In this model, the execution begins in a
sequential region and threads must be explicitly started to begin
a parallel region.
Listing \ref{lst:listing-pthreads} presents a sample code using the
\textit{Pthreads} library. The code was taken from
\cite{goncalves:OpenMPNotEasy} and shows a simple multiplication of two
matrices element-wise and summation of this multiplication.

The program begins its execution in a single thread and until line 17 only one
thread is running. When \texttt{pthread\_create} is called a thread is created
and the application enters a parallel region with two simultaneous threads. As
it happens inside a for loop, several threads are expected to be created. 

The strategy used for such parallelization is to devide the vectors in chunks
and delegating the multiplication of the elements inside these chunks among
threads, what can be seen in lines 14 and 15.
 
The main mechanism available for synchronizing thread executions is the
barrier. The \textit{Pthreads} library implements barriers as calls to
\texttt{pthread\_join}. A thread that reaches a barrier will wait for other
threads. Line 21 shows an example of thread synchronization using a barrier.

As the threads are supposed to write in a shared variable (\texttt{dot}), we
have to explicitly take care of the concurrent access to the variable, as seen
in Line 33 and 35, where the threads have to perform a lock at a mutex in order
to enter the critical region.

\begin{lstlisting}[language=C, basicstyle=\ttfamily\scriptsize, numbers=left,
                   frame=no, showspaces=false, showstringspaces=false,
                   caption={\textit{Pthreads} Sample Program}, captionpos=b,
                   numberstyle=\tiny,
                   xleftmargin=0.5cm,
                   label=lst:listing-pthreads, keywords={%
                       DATATYPE, pthread_t, pthread_create,
                       pthread_join, task_function, NULL, int, main,
                       void, printf, return%
                       },
                   otherkeywords={::, \#pragma, \#include, <<<,>>>, \&, \*, +, -, /, [, ], >, <}
                   ]
int A[SIZE], B[SIZE]; int dot = 0;
pthread_mutex_t lock ;
int main(int argc, char *argv []){ 
    int num_threads, i, part size ;
    pthread_t tid [MAX_THREADS];
    pthread_attr_t attr; 
    pthread_attr_init(&attr);
    /* Initialization vectors was supressed . */
    part_size = (SIZE + num_threads - 1) / num_threads;
    for (i=0; i < num_threads; i++){
        struct arg_struct *args = 
                malloc(sizeof(struct arg_struct));
        args->id = i;
        args->i_part = (i * part_size);
        args->e_part = MIN(((i + 1)* (part_size)), 
                           SIZE) ;
        pthread_create(&(tid[i]) ,&attr, vecDot, 
                       (void *) args) ;
    }
    for (i=0; i<num_threads; i++) { 
        pthread_join(tid[i], NULL);
    }
    printf("Final result: %d.\n", dot); 
    return 0;
}
void *vecDot (void *arguments){
    struct arg_struct *args = arguments;
    int i, partial_dot=0;
    for(i = args->i_part; i < args->e_part; i++){
        partial_dot += A[i] * B[i]; 
    }
    /* Critical region . */ 
    pthread_mutex_lock(&lock) ; 
    dot += partial_dot;
    pthread_mutex_unlock(&lock) ;
    pthread_exit(0); 
}
\end{lstlisting}

\subsection{OpenMP}

\textit{OpenMP} is an specification that defines a set of compiler directives,
libraries and environment variables that help exploring program parallelism.
The \textit{OpenMP} specification is kept by the \textit{OpenMP Architecture
Review Board}, composed by hardware manufacturers, and parallel software
developers and users.

\textit{OpenMP} implements the \textit{fork-join} model. An \textit{OpenMP}
program contains weaved sequential and parallel regions and always starts with
a sequential region, or master thread.  \textit{OpenMP} directives are
implemented in C/C++ and Fortran compilers. In C/C++ compilers the
specification of parallel executions is done using \textit{pragmas}, defined in
by using the \texttt{\#pragma} keyword.
The compilation process is not affected by the removal of the pragma,
which will result in the generation of a sequential version of the program.

\textit{OpenMP} directives follow the format \texttt{\#pragma directive
[clauses]}.  Each line contains at least one directive and may contain one or
more clauses. The main directives defined by the specification are related
to work sharing, task definition and dependencies, and synchronization.

Listing \ref{lst:listing-omp} presents an \textit{OpenMP} example. The
declaration of a parallel region with the \texttt{firstprivate} pragma on line
1 indicates the variable \texttt{aux\_dot} should be private to every thread
and initialized with the enclosing scope's value.  Line 3 will be executed by
only one thread, because of the \texttt{single} pragma.
The \texttt{for} in line 7 will be executed in parallel, with automatic work
division.  The pragma at line 12 defines a critical region which can only be
executed by a single thread at a time. The pragma at line 15 defines a
region that should only be executed by the master thread.

\begin{lstlisting}[language=C, basicstyle=\ttfamily\scriptsize, numbers=left,
                   frame=no, showspaces=false, showstringspaces=false,
                   caption={\textit{OpenMP} Sample Program}, captionpos=b,
                   numberstyle=\tiny,
                   xleftmargin=0.6cm,
                   label=lst:listing-omp, keywords={%
                       \#pragma,
                       omp, parallel, firstprivate,
                       single, omp_get_num_threads,
                       for, schedule, auto,
                       critical, master,
                       NULL, int, main,
                       void, printf, return%
                   },
                   otherkeywords={::, \#pragma, \#include, <<<,>>>, \&, \*, +, -, /, [, ], >, <}
                       ]
#pragma omp parallel firstprivate(aux_dot){
    #pragma omp single
    printf("Start of parallel region,
            number of threads: %d\n",
            omp_get_num_threads ());

    #pragma omp for schedule(auto)
    for(i = 0; i < SIZE; i++){
        aux_dot += A[i] * B[i];
    }

    #pragma omp critical
    dot += aux_dot;

    #pragma omp master
    printf("Result: %d.\n", dot);
}
\end{lstlisting}
